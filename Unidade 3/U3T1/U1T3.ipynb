{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GERAR O LIVRO COMO ARQUIVO PARA O GEPHI"
      ],
      "metadata": {
        "id": "INuM3pZufQgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import networkx as nx\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "\n",
        "# Baixar o livro do Project Gutenberg\n",
        "url = \"https://www.gutenberg.org/cache/epub/24344/pg24344.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "# Carregar o modelo de spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Dicionários para armazenar entidades\n",
        "entities = defaultdict(set)\n",
        "\n",
        "# Processar o texto para identificar categorias\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]:\n",
        "        entities[ent.label_].add(ent.text)\n",
        "\n",
        "# Criar grafo com NetworkX\n",
        "G = nx.Graph()\n",
        "\n",
        "# Adicionar nós ao grafo\n",
        "for label, names in entities.items():\n",
        "    for name in names:\n",
        "        G.add_node(name, label=label)\n",
        "\n",
        "# Criar arestas baseadas em coocorrência no mesmo parágrafo\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "for paragraph in paragraphs:\n",
        "    paragraph_doc = nlp(paragraph)\n",
        "    paragraph_entities = [ent.text for ent in paragraph_doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]]\n",
        "    for i, entity1 in enumerate(paragraph_entities):\n",
        "        for entity2 in paragraph_entities[i + 1:]:\n",
        "            if G.has_edge(entity1, entity2):\n",
        "                G[entity1][entity2][\"weight\"] += 1\n",
        "            else:\n",
        "                G.add_edge(entity1, entity2, weight=1)\n",
        "\n",
        "# Exportar para GEXF\n",
        "nx.write_gexf(G, \"graph_entities.gexf\")\n",
        "\n",
        "print(\"Arquivo 'graph_entities.gexf' gerado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsoMIa-fes9D",
        "outputId": "7b840cd4-667e-464f-f2da-54ad70f27f9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'graph_entities.gexf' gerado com sucesso!\n"
          ]
        }
      ]
    }
  ]
}